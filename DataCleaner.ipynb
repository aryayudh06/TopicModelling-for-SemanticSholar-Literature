{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hadik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hadik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hadik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\hadik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from deep_translator import GoogleTranslator\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"judul_scholar.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GenBank 2024 update</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[PDF] 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[PDF] The State of the World's Mangroves 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The voiceprivacy 2024 challenge evaluation plan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[PDF] 2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title\n",
       "0                              GenBank 2024 update\n",
       "1                                       [PDF] 2024\n",
       "2    [PDF] The State of the World's Mangroves 2024\n",
       "3  The voiceprivacy 2024 challenge evaluation plan\n",
       "4                                       [PDF] 2024"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = GoogleTranslator(source='auto', target='en')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def CleanText(text):\n",
    "    if not isinstance(text, str):  # Pastikan input adalah string\n",
    "        return \"\"\n",
    "    \n",
    "    text = re.sub(r\"\\[.*?\\]\", \"\", text)  # Hapus teks dalam kurung siku []\n",
    "    text = re.sub(r\"\\b\\d{4}\\b\", \"\", text)  # Hapus tahun (4 digit angka yang berdiri sendiri)\n",
    "    text = text.strip().lower()  # Konversi ke huruf kecil\n",
    "    \n",
    "    # Tokenisasi\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Hapus stopwords & lakukan lemmatization\n",
    "    stop_words = set(stopwords.words('english'))  # Inisialisasi di dalam fungsi\n",
    "    lemmatizer = WordNetLemmatizer()  # Inisialisasi di dalam fungsi\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words and word.isalnum()]\n",
    "    \n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "def Translate(text):\n",
    "    return translator.translate(text) if text else None\n",
    "\n",
    "data[\"title\"] = data[\"title\"].apply(CleanText)\n",
    "data[\"title\"] = data[\"title\"].apply(Translate)\n",
    "data = data.replace(\"\", None).dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  title\n",
      "0                                        genbank update\n",
      "1                                  state world mangrove\n",
      "2                voiceprivacy challenge evaluation plan\n",
      "3         wikipathways next generation pathway database\n",
      "4     ieee international conference robotics automat...\n",
      "...                                                 ...\n",
      "2670  contribution fishery aquaculture global protei...\n",
      "2671  atomically dispersed dual metal site bifunctio...\n",
      "2672                                          childhood\n",
      "2673                                     multimorbidity\n",
      "2674                                        vaccinology\n",
      "\n",
      "[2675 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"judul_scholar_clean.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
